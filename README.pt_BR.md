 \[**[üáßüá∑ Portugu√™s](README.pt_BR.md)**\] \[[üá∫üá∏ English](README.md)\]

<br>

# <p align="center"> 6- Social [Buzz AI]() -Detec√ß√£o de Fake News usando Machine Learning


<br><br>

## 1. Introdu√ß√£o

<br>

- **Fake news** s√£o informa√ß√µes falsas disseminadas principalmente em redes sociais, podendo causar s√©rios impactos pol√≠ticos, sociais e de sa√∫de p√∫blica.
- O estudo se prop√¥s a aplicar algoritmos de *Machine Learning* (ML) para detectar not√≠cias falsas automaticamente, oferecendo alternativa tecnol√≥gica ao combate desse problema.


<br><br>

## 2. Objetivos do Estudo

<br>

- Testar e comparar diferentes algoritmos de ML para detectar fake news.
- Avaliar o desempenho de cada modelo em precis√£o, sensibilidade e especificidade.
- Propor uma solu√ß√£o automatizada, replic√°vel e √∫til √† sociedade.



<br><br>


## 3. Metodologia Detalhada

<br>

- **Base de dados:** Obtida na plataforma Kaggle, composta por artigos fakes e verdadeiros, ambos com colunas de t√≠tulo, texto, assunto e data.
    - Fake: 23.481 linhas
    - True: 21.417 linhas

<br>

- **Ferramentas utilizadas:** Python e as bibliotecas Pandas, NumPy, Matplotlib, Seaborn, Scikit-Learn, NLTK.

<br>

- **Processamento dos dados:**
    - Carregamento dos datasets e identifica√ß√£o da coluna alvo (target: 'fake' ou 'true').
    - Uni√£o das tabelas e embaralhamento dos registros com a biblioteca `Shuffle` para evitar vieses.
    - Remo√ß√£o das colunas de data e t√≠tulo para focar no texto.
    - Normaliza√ß√£o do texto:
        - Transforma√ß√£o para letras min√∫sculas.
        - Remo√ß√£o de pontua√ß√£o (biblioteca `string`).
        - Elimina√ß√£o dos 'stopwords' (NLTK).
    - An√°lise visual dos termos mais frequentes por meio de *WordCloud*.

<br>

- **Valida√ß√£o dos modelos:** T√©cnica **Holdout**, separando dados de treino e teste objetivando avaliar o desempenho de cada algoritmo.


<br><br>


## 4. Algoritmos Aplicados

<br>

Cinco modelos supervisionados foram treinados e avaliados:

<br><br>

| Modelo | Acur√°cia | Observa√ß√µes |
| :-- | :-- | :-- |
| Regress√£o Log√≠stica | 98,92% | Alta precis√£o, matriz de confus√£o mostra baixo √≠ndice de erro. |
| Decision Tree | 99,6% | Melhor desempenho geral e menor erro nos resultados. |
| Random Forest | 98,74% | Bom desempenho, matriz de confus√£o consistente. |
| Support Vector Machine | 99,5% | √ìtima acur√°cia e precis√£o, modelo robusto para textos. |
| K-Nearest Neighbors (KNN) | 60,84% | Baixo desempenho, elevado n√∫mero de falsos negativos. |

<br><br>

**M√©tricas computadas via matriz de confus√£o** (incluindo VP, VN, FP, FN) e valores de precis√£o e sensibilidade detalhados para cada modelo.

#### Exemplo: Matriz de confus√£o simplificada (Decision Tree)

- Verdadeiros Positivos (VP): 4.711
- Falsos Positivos (FP): 13
- Falsos Negativos (FN): 22
- Verdadeiros Negativos (VN): 4.234

<br><br>


## 5. M√©tricas de Avalia√ß√£o

- **Acur√°cia:** Percentual total de acertos do modelo.
- **Precis√£o:** Qu√£o corretamente detecta fake news.
- **Sensibilidade:** Capacidade de identificar corretamente as verdadeiras fake news.
- **Especificidade:** Capacidade de acertar os valores negativos (verdadeiras).

<br>

#### Desempenho dos Modelos

<br><br>

| Modelo | Precis√£o | Sensibilidade | Especificidade |
| :-- | :-- | :-- | :-- |
| Regress√£o Log√≠stica | 98% | 99% | 98% |
| Decision Tree | 98,5% | 99% | 99% |
| Random Forest | 98,5% | 99% | 98% |
| SVM | 99% | 99% | 99% |
| KNN | 99% | 57% | 19% |

<br><br>


## 6. Resultados Detalhados

<br>

- Quatro dos cinco modelos atingiram acur√°cia superior a 90%.
- O KNN obteve desempenho insatisfat√≥rio, principalmente devido ao alto n√∫mero de **falsos negativos** (sensibilidade de 57%).
- Decision Tree e SVM destacaram-se como os mais eficientes.
- O processo de tratamento de dados e sele√ß√£o de features foi fundamental para o sucesso dos modelos.


<br><br>

## 7. Limita√ß√µes e Propostas Futuras

<br>

- **Limita√ß√µes do trabalho:** Dificuldade para encontrar base de dados padronizada (especialmente em portugu√™s), poucos sistemas aplicados √† realidade brasileira.
- **Perspectivas:** Avaliar novos algoritmos (Naive Bayes, Boosting, K-means, Gradiente Descendente), aplicar outras t√©cnicas de valida√ß√£o, ampliar bases em portugu√™s, incluir valida√ß√£o cruzada (K-fold, Leave-one-out) e desenvolver aplica√ß√µes web para uso p√∫blico


<br><br>

